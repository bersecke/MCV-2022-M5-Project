{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pickle as pkl\n",
    "import torch\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from networks import EmbeddingNet, TripletNetAdapted, TripletNetAdaptedText\n",
    "from flickrDataSet import *\n",
    "from matplotlib import pyplot as plt\n",
    "from embeddings_utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_path = 'TripletNet_taskA_2layerNet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_text(word_embs, axis = 0):\n",
    "    return np.sum(word_embs, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TripletNetAdapted(\n",
       "  (emb_net): EmbeddingNet(\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (text_net): EmbeddingNet(\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_emb_dim = 4096\n",
    "text_emb_dim = 300\n",
    "\n",
    "embedding_net_img = EmbeddingNet(emd_dim=img_emb_dim)\n",
    "embedding_net_text = EmbeddingNet(emd_dim=text_emb_dim)\n",
    "model = TripletNetAdapted(embedding_net_img, embedding_net_text)\n",
    "# model = TripletNetAdaptedText(embedding_net_img, embedding_net_text)\n",
    "\n",
    "\n",
    "print('Loading model...')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "# train_data = FlickrDataset('./dataset/train_img_embs.pkl', './dataset/train_text_embs.pkl', aggregation=aggregation_text, train= True)\n",
    "test_data = FlickrDataset('./dataset/test_img_embs.pkl', './dataset/test_text_embs.pkl', aggregation=aggregation_text, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "encoded_imgs = []\n",
    "encoded_captions = []\n",
    "all_embs = []\n",
    "labels = []\n",
    "\n",
    "for ind in range(len(test_data)):\n",
    "    img, texts = test_data.getAllCaptions(ind)\n",
    "    img_emb = model.get_embedding_img(torch.from_numpy(img).to(device)).data.cpu().numpy()\n",
    "    encoded_imgs.append(img_emb)\n",
    "    texts_embs = [model.get_embedding_text(torch.from_numpy(tx).to(device)).data.cpu().numpy() for tx in texts]\n",
    "    encoded_captions.append(texts_embs)\n",
    "    all_embs.append(img_emb)\n",
    "    all_embs += texts_embs\n",
    "    labels += [ind for i in range(1 + len(texts_embs))]\n",
    "\n",
    "encoded_imgs = np.array(encoded_imgs)\n",
    "encoded_captions = np.array(encoded_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bestK(train_data, test_data, k=5, method=cv2.HISTCMP_BHATTACHARYYA, sortReverse=False):\n",
    "    precs_per_image = []\n",
    "    for ind, elem in tqdm(enumerate(test_data)):\n",
    "        results = getDistances(method, train_data, elem[1])\n",
    "        results = sorted([(v[1], v[0], k) for (k, v) in results.items()], reverse=sortReverse)\n",
    "        precs_per_image.append((elem[0], [res[2] for res in results[:k]]))\n",
    "        # classes = [res[1] for res in results[:k]]\n",
    "        # precs_per_image.append(classes.count(elem['label']) / k)\n",
    "    \n",
    "    return precs_per_image\n",
    "\n",
    "def embeddingsRawMap(embeddingsTxt, embeddingsImgs, labelsMap, captionsPerImage = 5):\n",
    "    embeddingsLabelMap = []\n",
    "    embeddingsImageMap = []\n",
    "    i = 0\n",
    "    for ind, emb in enumerate(embeddingsTxt):\n",
    "        imageInd  = ind // captionsPerImage\n",
    "        embeddingsLabelMap.append((labelsMap[imageInd]['sentences'][i]['raw'], labelsMap[imageInd]['filename'], emb))\n",
    "        if i == 0:\n",
    "            embeddingsImageMap.append((labelsMap[imageInd]['filename'], embeddingsImgs[imageInd]))\n",
    "        i = (i + 1) % captionsPerImage\n",
    "\n",
    "    return embeddingsImageMap, embeddingsLabelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(encoded_captions.reshape((5000, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset/test.json', 'rb') as op:\n",
    "    textsMap = json.load(op)\n",
    "\n",
    "embeddingsImageMap, embeddingsLabelMap = embeddingsRawMap(encoded_captions.reshape(5000,128), encoded_imgs, textsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval system with distance metric:  Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "tests = [('Hellinger', cv2.HISTCMP_BHATTACHARYYA, False) ]#, ('Correlation', cv2.HISTCMP_CORREL, True), ('Chi Square', cv2.HISTCMP_CHISQR, False), ('Intersection', cv2.HISTCMP_INTERSECT, True)]\n",
    "all_results_p1 = {}\n",
    "preds_10 = None\n",
    "for data in tests:\n",
    "    print('Retrieval system with distance metric: ', data[0])\n",
    "    preds_10 = compute_bestK(embeddingsLabelMap, embeddingsImageMap[:5],10,data[1],data[2])\n",
    "#     prec_at_1 = np.mean([elem[1][0].count(elem[0]) for elem in preds_10])\n",
    "#     prec_at_5 = np.mean([elem[1][:5].count(elem[0]) / 5 for elem in preds_10])\n",
    "#     prec_at_10 = np.mean([elem[1][:10].count(elem[0]) / 10 for elem in preds_10])\n",
    "#     all_results_p1[data[0]] = []\n",
    "#     for i in range(1,11):\n",
    "#         all_results_p1[data[0]].append(np.mean([elem[1][:i].count(elem[0]) / i for elem in preds_10]))\n",
    "#     print(f'Prec@1: {prec_at_1}', f'Prec@5: {prec_at_5}', f'Prec@10: {prec_at_10}')\n",
    "\n",
    "# for key, vals in all_results_p1.items():\n",
    "#     plt.plot(list(range(1,len(vals) + 1)), vals, label=key)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1007129816.jpg', ['A man smoking a cigarette and wearing a NY baseball cap is looking down at a camera.', 'A man smoking a cigarette and wearing a yankees hat trying to operate a camera.', 'A British gentleman, dressed in full military uniform, waving his hat with a background of people sitting back and looking out onto the waterway.', 'Man in black hat sipping wine.', 'Man wearing red uniform holding a black hat in the air with his right hand.', 'An older man with a cigarette in his mouth and a ball cap inspects his camera.', 'Seated man with red hat and green shirt is talking on the phone.', 'A man wears an orange hat and glasses.', 'A young man in a blue poncho smoking a cigarette.', 'A man with a pensive look on his face shave off his beard.']), ('1009434119.jpg', ['A cat is looking down from on top of a sign.', 'A light brown dog jumps through a ring of fire while two people watch.', 'A dog goes through an obstacle course while his owner runs beside him.', 'A black dog sprints near the blue fence.', 'A bald man demonstarting how high his brown and black dog can jump.', 'A black and white dog jumping over a steeple vault at a competition', 'A man and his dog watch the sunset from a bench.', 'A black and white dog jumps over a hurdle.', 'A small black dog jumping over gates', 'A black and white dog is jumping fences in a dog show.']), ('101362133.jpg', [\"A boy wearing an orange doritos shirt looks like he's about to jump off of a piece of furniture.\", 'An oriental person in a red shirt and black pants crouching over a purse on concrete.', 'Girl hits a ball and the catcher looks on.', 'A kid is holding a broom and sweeping his property.', 'A man in white pants and a blue shirt is kicking a yellow boxing bag.', 'A man on the edge of a wall about to fall off.', 'A cat is looking down from on top of a sign.', 'A small boy dressed in a black sweatshirt with a logo on it, holds a red bat in front of blue stadium seats.', 'The girl with the red belt is kicking a pad that the person in black is holding.', 'A boy wearing jeans leaps in the air and shows his shadow below.']), ('102617084.jpg', ['A man dressed in all black is wearing shades and standing in snow and there is a red vehicle in back of him.', 'A group of 11 people in winter wear such as beanies, skiing jackets, gloves and backpacks are standing in snow paddles outside a house made of ice blocks while a person in front of the door seems to be leading them.', \"A group of people wearing snowshoes, and dressed for winter hiking, is standing in front of a building that looks like it's made of blocks of ice.\", 'A man in blue watches a family walk by while sitting in the snow.', 'Five snowmobile riders all wearing helmets and goggles line up in a snowy clearing in a forest in front of their snowmobiles; they are all wearing black snow pants and from left to right they are wearing a black coat, white coat, red coat, blue coat, and black coat.', 'A man is sitting in the snow watching as a group of people are walking by.', 'Four people dressed for warm weather out on a street walking.', 'A man in a yellow coat tends a fire, a boy in a parka watches.', 'Two workers wearing bright protective overcoats, shovel snow out of the way of passing residents.', 'A man in a blue jacket is standing in front of a small group of people.']), ('10287332.jpg', ['A man in a white hoodie is sitting on top of bamboo scaffolding near the roof of a building holding a spade.', 'A man wearing a blue shirt trying to get something with a pole from the roof of the room.', 'A brick wall has colorful graffiti on it.', 'A man carrying a large stack of metal poles over his shoulder.', 'Man scaling wall with fire in hand', 'A man carrying steel beams across a lumberyard.', 'The man is standing on the white wall in front of the building.', 'Three men, one on a ladder, work on a roof.', 'Man skates along cement wall.', 'A man is walking near a very colorful wall.'])]\n"
     ]
    }
   ],
   "source": [
    "print(preds_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(all_embs)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/export/home/group05/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "#doesn't work with all the samples, too heavy\n",
    "from embeddings_utils import build_knn\n",
    "knn = build_knn(all_embs, labels, 5)\n",
    "print(100.0 * knn.score(all_embs,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training One vs Rest...\n",
      "Predicting probas...\n",
      "Computing MAP...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6000, 60]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-feccec9e192b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing MAP...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0maps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    232\u001b[0m     return _average_binary_score(\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0maverage_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    204\u001b[0m     ):\n\u001b[1;32m    205\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \"\"\"\n\u001b[1;32m    858\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/M5env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6000, 60]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Y = label_binarize(labels, classes=[*range(len(test_data))])\n",
    "Y_test = label_binarize(labels[:60], classes=[*range(len(test_data))])\n",
    "\n",
    "print('Training One vs Rest...')\n",
    "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=8))\n",
    "clf.fit(all_embs, Y)\n",
    "\n",
    "print('Predicting probas...')\n",
    "y_score = clf.predict_proba(all_embs[:60])\n",
    "\n",
    "# precision recall curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "aps = []\n",
    "print('Computing MAP...')\n",
    "for i in range(len(test_data)):\n",
    "    ap = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "    aps.append(ap)\n",
    "#     precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "#                                                         y_score[:, i])\n",
    "#     plt.plot(recall[i], precision[i], lw=2, label=f'{mit_classes[i]} - {ap:.3f}')\n",
    "print(np.mean(aps))\n",
    "# plt.xlabel(\"recall\")\n",
    "# plt.ylabel(\"precision\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.title(\"precision vs. recall curve\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group05/anaconda3/envs/M5env/lib/python3.7/site-packages/umap/spectral.py:261: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n",
      "/home/group05/anaconda3/envs/M5env/lib/python3.7/site-packages/umap/spectral.py:261: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n",
      "/home/group05/anaconda3/envs/M5env/lib/python3.7/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #UMAP\n",
    "# # compute the umap image representation\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "def plot_embeddings_umap(embeddings_cl, embeddings_to_plot, labels_cl):\n",
    "        plt.figure(figsize=(15,15))\n",
    "        umap_emb = umap.UMAP(n_neighbors=4, min_dist=0.3, metric='correlation')\n",
    "        umap_emb.fit(embeddings_cl)\n",
    "        embedding = umap_emb.transform(embeddings_to_plot)\n",
    "        labels = np.unique(labels_cl)\n",
    "\n",
    "        for idx, label in enumerate(labels):\n",
    "            label_features = [embedding[i] for i, x in enumerate(labels_cl) if x == label]\n",
    "            plt.scatter(\n",
    "                [x[0] for x in label_features],\n",
    "                [x[1] for x in label_features],\n",
    "                c=np.array([color[idx]]),\n",
    "                label=label,\n",
    "                # s=np.ones(len(test_classes)),\n",
    "            )\n",
    "\n",
    "        # plt.legend(loc='best')\n",
    "\n",
    "        for idx, label in enumerate(labels):\n",
    "            label_features = [embedding[i] for i, x in enumerate(labels_cl) if x == label]\n",
    "            xtext, ytext = np.median(label_features, axis=0)\n",
    "            txt = plt.text(xtext, ytext, label)\n",
    "            txt.set_path_effects([\n",
    "                PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "                PathEffects.Normal()])\n",
    "\n",
    "        plt.title('2D UMAP representation of the image features')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_embeddings_umap(all_embs, all_embs[:12], labels[:12])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3403cc93a53f62706eb00774ee9b4a3b3eb9f2d81f53e3496b8b070b38dadcd0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
