{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfantastic5\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\wandb\\run-20220412_132506-6ghdbqvw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fantastic5/M5-Image-to-text/runs/6ghdbqvw\" target=\"_blank\">gentle-spaceship-5</a></strong> to <a href=\"https://wandb.ai/fantastic5/M5-Image-to-text\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import wandb\n",
    "wandb.init(project='M5-Image-to-text', entity='fantastic5')\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from trainer import fit\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, emd_dim = 4096):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(emd_dim, 256),\n",
    "                                nn.PReLU(),\n",
    "                                )\n",
    "\n",
    "    def forward(self, x1):\n",
    "        output1 = self.fc1(x1)\n",
    "        return output1\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "class TripletNetAdapted(nn.Module):\n",
    "    def __init__(self, image_embedding_net, word_embedding_net):\n",
    "        super(TripletNetAdapted, self).__init__()\n",
    "        self.image_net = image_embedding_net\n",
    "        self.text_net = word_embedding_net\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = self.image_net(x1)\n",
    "        output2 = self.text_net(x2)\n",
    "        output3 = self.text_net(x3)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_text(word_embs, axis = 0):\n",
    "    return np.sum(word_embs, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrDataSet import *\n",
    "\n",
    "# Prepare the dataset\n",
    "train_data = FlickrDataset('./dataset/train_img_embs.pkl', './dataset/train_text_embs.pkl', aggregation=aggregation_text, train= True)\n",
    "test_data = FlickrDataset('./dataset/test_img_embs.pkl', './dataset/test_text_embs.pkl', aggregation=aggregation_text, train= False)\n",
    "\n",
    "triplet_train_dataset = TripletFlickrDataset(train_data) # Returns triplet of images and target same/different\n",
    "triplet_test_dataset = TripletFlickrDataset(test_data)\n",
    "\n",
    "batch_size = 64\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9144233, -0.       , -0.       , ..., -0.       , -0.       ,\n",
       "       -0.       ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = train_data[2]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\flickrDataSet.py\", line 67, in __getitem__\n    img1, text_pos = self.flickr_dataset[index]\n  File \"c:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\flickrDataSet.py\", line 36, in __getitem__\n    img, text = self.train_data[index], self.img_texts[index][random.randint(0,len(self.img_texts[index]))]\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000026?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(triplet_train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000026?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch_idx)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000026?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1203\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1200'>1201</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1201'>1202</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1202'>1203</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1229\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1226'>1227</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1227'>1228</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1228'>1229</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=1229'>1230</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/_utils.py?line=429'>430</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/_utils.py?line=430'>431</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/_utils.py?line=431'>432</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/_utils.py?line=432'>433</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/_utils.py?line=433'>434</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\flickrDataSet.py\", line 67, in __getitem__\n    img1, text_pos = self.flickr_dataset[index]\n  File \"c:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\flickrDataSet.py\", line 36, in __getitem__\n    img, text = self.train_data[index], self.img_texts[index][random.randint(0,len(self.img_texts[index]))]\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(triplet_train_loader):\n",
    "    print(batch_idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galve\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000025?line=20'>21</a>\u001b[0m     log_interval \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000025?line=21'>22</a>\u001b[0m     \u001b[39m## Training !!!\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000025?line=22'>23</a>\u001b[0m     fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000025?line=23'>24</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), save_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/test.ipynb#ch0000025?line=24'>25</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\trainer.py:26\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics, start_epoch, wandb_plot)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=22'>23</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=24'>25</a>\u001b[0m \u001b[39m# Train stage\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=25'>26</a>\u001b[0m train_loss, metrics \u001b[39m=\u001b[39m train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=27'>28</a>\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Train set: Average loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, n_epochs, train_loss)\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics:\n",
      "File \u001b[1;32mc:\\Users\\galve\\Master\\M5\\MCV-2022-M5-Project\\Week5\\trainer.py:54\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=50'>51</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=51'>52</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=54'>55</a>\u001b[0m     target \u001b[39m=\u001b[39m target \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/galve/Master/M5/MCV-2022-M5-Project/Week5/trainer.py?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mtype\u001b[39m(data) \u001b[39min\u001b[39;00m (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:359\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=356'>357</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=357'>358</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=358'>359</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:305\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=302'>303</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=303'>304</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=304'>305</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:933\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m pin_memory_thread \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m     target\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39m_pin_memory_loop,\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m     args\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_result_queue, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_queue,\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=929'>930</a>\u001b[0m           torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mcurrent_device(),\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=930'>931</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread_done_event))\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=931'>932</a>\u001b[0m pin_memory_thread\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=932'>933</a>\u001b[0m pin_memory_thread\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=933'>934</a>\u001b[0m \u001b[39m# Similar to workers (see comment above), we only register\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=934'>935</a>\u001b[0m \u001b[39m# pin_memory_thread once it is started.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/site-packages/torch/utils/data/dataloader.py?line=935'>936</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread \u001b[39m=\u001b[39m pin_memory_thread\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\threading.py:857\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=854'>855</a>\u001b[0m         \u001b[39mdel\u001b[39;00m _limbo[\u001b[39mself\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=856'>857</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_started\u001b[39m.\u001b[39;49mwait()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=555'>556</a>\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=556'>557</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=557'>558</a>\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=558'>559</a>\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=299'>300</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=300'>301</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=301'>302</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=302'>303</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/galve/Anaconda3/envs/Torch/lib/threading.py?line=303'>304</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "img_emb_dim = 4096\n",
    "text_emb_dim = 300\n",
    "\n",
    "save_path = 'TripletNet.pth'\n",
    "\n",
    "embedding_net_img = EmbeddingNet(emd_dim=img_emb_dim)\n",
    "embedding_net_text = EmbeddingNet(emd_dim=text_emb_dim)\n",
    "model = TripletNetAdapted(embedding_net_img, embedding_net_text)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    margin = 0.5\n",
    "    loss_fn = nn.TripletMarginLoss(margin)\n",
    "    lr = 1e-3\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.9, last_epoch=-1)\n",
    "    n_epochs = 100\n",
    "    log_interval = 1000\n",
    "    ## Training !!!\n",
    "    fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "else:\n",
    "    print('Loading model...')\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.to(device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bc29f060ed23a123f6d9ca4fac8af0775aca92f5b2f5a596f9ae7b118c743e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
